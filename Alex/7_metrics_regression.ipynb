{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"mpo2pkNIHR8k"},"outputs":[],"source":["import pathlib\n","import seaborn as sns\n","import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras import layers\n","from sklearn import svm\n","from sklearn import model_selection\n","from statsmodels.tools.eval_measures import mse\n","from sklearn.metrics import mean_absolute_error\n","import keras.layers\n","import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","pd.options.display.float_format = '{:.5f}'.format\n","from datetime import datetime\n","from google.colab import files\n","import re\n","from sklearn import preprocessing\n","from sklearn.metrics import r2_score\n","from sklearn.metrics import mean_squared_error\n","from sklearn.metrics import mean_absolute_error\n","from sklearn.model_selection import KFold\n","from sklearn.utils import shuffle\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5a0MErvZFKrs"},"outputs":[],"source":["datasetbig = pd.read_csv(\"/content/sample_data/base_dataset.csv\")\n","# If you are using the extra dataset please set this to true\n","bol_extra_dataset = False"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qWpoLhgb7ni5"},"outputs":[],"source":["class PrintDot(keras.callbacks.Callback):\n","  def on_epoch_end(self,epoch,logs):\n","    if epoch % 100 == 0: print(\"\")\n","    print(\".\",end=\"\")\n","\n","def popAndGetPredictionLabels(bol_extra_dataset,train_dataset):\n","\n","  if bol_extra_dataset == False:\n","    train_labels=[\n","      [\"success_rate\",train_dataset.pop(\"success_rate\")],\n","      [\"collision_rate\", train_dataset.pop(\"collision_rate\")],\n","      [\"timeout_rate\", train_dataset.pop(\"timeout_rate\")],\n","      [\"average_path_length\", train_dataset.pop(\"average_path_length\")],\n","      [\"average_time_diff\", train_dataset.pop(\"average_time_diff\")]\n","    ]\n","  else:\n","    train_labels=[\n","      [\"success_rate\",train_dataset.pop(\"success_rate\")],\n","      [\"collision_rate\", train_dataset.pop(\"collision_rate\")],\n","      [\"average_collision_amount\", train_dataset.pop(\"average_collision_amount\")],\n","      [\"timeout_rate\", train_dataset.pop(\"timeout_rate\")],\n","      [\"timeout_collision_rate\",train_dataset.pop(\"timeout_collision_rate\")],\n","      [\"average_path_length\", train_dataset.pop(\"average_path_length\")],\n","      [\"average_time_diff\", train_dataset.pop(\"average_time_diff\")]\n","\n","    ]\n","  return train_labels\n","\n","def get_group(dataset, performanceMetric):\n","  return dataset.loc[dataset[\"Label\"]== performanceMetric]\n","\n","def get_best_of(dataset,performanceMetric,measure):\n","  dataset = get_group(dataset,performanceMetric)\n","  result = dataset[dataset[measure] == dataset[measure].min()]\n","  return result\n","\n","def norm(dataset):\n","  train_stats = dataset.describe()\n","  train_stats = train_stats.transpose()\n","  return ((dataset-train_stats[\"min\"])/(train_stats[\"max\"]-train_stats[\"min\"]))\n","\n","def is_unique(s):\n","    a = s.to_numpy()\n","    return (a[0] == a).all()\n","\n","def checkForConstants(dataset):\n","  for column in dataset:\n","      if is_unique(dataset[column]) == True:\n","          print(\"Dropping\", column)\n","          dataset=dataset.drop(columns=column)\n","  return dataset\n","\n","def getMeans(bol_extra_dataset, dataset):\n","  if(bol_extra_dataset == False):\n","    means = [\n","      [\"mean_success_rate\",             dataset[\"success_rate\"].mean()],\n","      [\"mean_collision_rate\",           dataset[\"collision_rate\"].mean()],\n","      [\"mean_timeout_rate\",             dataset[\"timeout_rate\"].mean()],\n","      [\"mean_average_path_length\",      dataset[\"average_path_length\"].mean()],\n","      [\"mean_average_time_diff\",        dataset[\"average_time_diff\"].mean()]\n","      ]\n","  else:\n","    means = [\n","      [\"mean_success_rate\",             dataset[\"success_rate\"].mean()],\n","      [\"mean_collision_rate\",           dataset[\"collision_rate\"].mean()],\n","      [\"mean_average_collision_amount\", dataset[\"average_collision_amount\"].mean()],\n","      [\"mean_timeout_rate\",             dataset[\"timeout_rate\"].mean()],\n","      [\"mean_timeout_collision_rate\",   dataset[\"timeout_collision_rate\"].mean()],\n","      [\"mean_average_path_length\",      dataset[\"average_path_length\"].mean()],\n","      [\"mean_average_time_diff\",        dataset[\"average_time_diff\"].mean()]\n","      ]\n","  return means\n","\n","def get_numpy_labels(bol_extra_dataset,dataset):\n","  if(bol_extra_dataset==False):\n","    success_rate        =np.hstack([dataset[:,2:3]])\n","    collision_rate      =np.hstack([dataset[:,3:4]])\n","    timeout_rate        =np.hstack([dataset[:,4:5]])\n","    average_path_length =np.hstack([dataset[:,5:6]])\n","    average_time_diff   =np.hstack([dataset[:,6:7]])\n","    label_array=[success_rate,collision_rate,timeout_rate,average_path_length,average_time_diff]\n","  else:\n","    success_rate            =np.hstack([dataset[:,2:3]])\n","    collision_rate          =np.hstack([dataset[:,3:4]])\n","    average_collision_amount=np.hstack([dataset[:,4:5]])\n","    timeout_rate            =np.hstack([dataset[:,5:6]])\n","    timeout_collision_rate  =np.hstack([dataset[:,6:7]])\n","    average_path_length     =np.hstack([dataset[:,7:8]])\n","    average_time_diff       =np.hstack([dataset[:,8:9]])\n","    label_array=[success_rate,collision_rate,average_collision_amount,\n","                 timeout_rate,timeout_collision_rate,average_path_length,average_time_diff]\n","  return label_array"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1jaikoBXu7Sc"},"outputs":[],"source":["datasetbig=shuffle(datasetbig,random_state=0)"]},{"cell_type":"code","source":["datasetbig"],"metadata":{"id":"hofMmFZiGmR4"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iEIdvj1_tZFG"},"outputs":[],"source":["pd.set_option('display.max_columns', None)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BTJpsnNQebff"},"outputs":[],"source":["rlca = datasetbig[datasetbig[\"rlca\"] == 1]\n","crowdnav = datasetbig[datasetbig[\"crowdnav\"] == 1]\n","\n","indoor = datasetbig[datasetbig[\"indoor_map_type\"] == 1]\n","outdoor = datasetbig[datasetbig[\"outdoor_map_type\"] == 1]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"erUZrloSFOxA"},"outputs":[],"source":["# choose dataset to work with\n","dataset = datasetbig"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TxiRaTqAFYj3"},"outputs":[],"source":["dataset = dataset.drop(columns=[\"teb\"])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1InrQKMB92qJ"},"outputs":[],"source":["means = getMeans(bol_extra_dataset,dataset)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MNqcfKP7KWR-"},"outputs":[],"source":["dataset = checkForConstants(dataset)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_6rtPC9uumgF"},"outputs":[],"source":["nump=dataset[\"robot_max_speed\"].to_numpy()"]},{"cell_type":"code","source":["dataset[\"dyn_obstacle_occupation\"] = dataset[\"number_dynamic_obstacles\"]*dataset[\"average_obstalce_size\"]"],"metadata":{"id":"k2JFqCRP3_Ug"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VBaoDMSTvIXd"},"outputs":[],"source":["train_dataset = dataset.sample(frac=0.8, random_state = 0)\n","test_dataset = dataset.drop(train_dataset.index)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AQszkdb7v_bY"},"outputs":[],"source":["train_dataset_array = np.array(train_dataset)\n","test_dataset_array = np.array(test_dataset)\n","\n","output_train_array=get_numpy_labels(bol_extra_dataset,train_dataset_array)\n","output_test_array=get_numpy_labels(bol_extra_dataset,test_dataset_array)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iOfSOi6wHsnt"},"outputs":[],"source":["train_labels = popAndGetPredictionLabels(bol_extra_dataset,train_dataset)\n","test_labels = popAndGetPredictionLabels(bol_extra_dataset,test_dataset)"]},{"cell_type":"markdown","metadata":{"id":"mpJK3e3hr1Uy"},"source":["Scaling data via Standard Scaler"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"v94gWshMyIWw"},"outputs":[],"source":["normed_train_data_std = preprocessing.StandardScaler().fit_transform(train_dataset)\n","normed_test_data_std = preprocessing.StandardScaler().fit_transform(test_dataset)"]},{"cell_type":"markdown","metadata":{"id":"PzvkeBnmsqUR"},"source":["Scaling data via Formular"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Vqqc8zktt7fb"},"outputs":[],"source":["normed_train_data_form=norm(train_dataset)\n","normed_test_data_form=norm(test_dataset)"]},{"cell_type":"markdown","metadata":{"id":"SRgI02UFFMab"},"source":["# Linear Regression"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3Vuga6VTDjiZ"},"outputs":[],"source":["# for linear regression we need only a train and test set\n","normed_train_data = normed_train_data_form\n","normed_test_data = normed_test_data_form"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0imgCXBa1uW6"},"outputs":[],"source":["dataset_corr = dataset.corr()\n","success_rate_dict = dataset_corr[\"success_rate\"]\n","collision_rate_dict = dataset_corr[\"collision_rate\"]\n","timeout_rate_dict = dataset_corr[\"timeout_rate\"]\n","average_path_length_dict  = dataset_corr[\"average_path_length\"]\n","average_time_diff_dict  = dataset_corr[\"average_time_diff\"]\n","\n","dictList = [success_rate_dict,collision_rate_dict,timeout_rate_dict,\n","            average_path_length_dict,average_time_diff_dict]\n","\n","keyList=[\"success_rate\",\"collision_rate\",\"timeout_rate\",\"average_path_length\",\n"," \"average_time_diff\",\"width\",\"height\"]\n","\n","for idx in range(0,len(dictList)):\n","  for key in keyList:\n","    del dictList[idx][key]\n","  dictList[idx] = sorted(dictList[idx].items(), key=lambda x:abs(x[1]),reverse=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dvS_sewYqPdz"},"outputs":[],"source":["import warnings\n","warnings.filterwarnings(\"ignore\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kDl_GlEUrlon"},"outputs":[],"source":["performance_table_forward_search = pd.DataFrame()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8Jw39woknd9m","colab":{"base_uri":"https://localhost:8080/"},"outputId":"9a18b2f3-eaaf-425d-e6f9-f61e38ce7901"},"outputs":[{"output_type":"stream","name":"stdout","text":["##################################\n","index 0\n","##################################\n","22/22 [==============================] - 0s 1ms/step\n","##################################\n","Finished | 200  | success_rate  | ['dyn_obstacle_occupation']\n","##################################\n"]}],"source":["# create feature list\n","dictList2 = dictList\n","\n","featrueTuple = dictList2[0]\n","\n","# get only training parameter names\n","feature_List = [i[0] for i in featrueTuple]\n","\n","epochs = [200,500,1000]\n","for idx_dictList in range(0,len(dictList)):\n","  print(\"##################################\")\n","  print(\"index\", idx_dictList)\n","  print(\"##################################\")\n","  for epoch in epochs:\n","    features = feature_List.copy()\n","    best_features = []\n","    parameterList =  []\n","    performanceList = []\n","    while len(features) != 0:\n","      for feature in features:\n","\n","          train_params = []\n","\n","          for element in best_features:\n","            train_params.append(element)\n","          train_params.append(feature)\n","\n","          parameterList.append(train_params)\n","\n","          # get subset of training data\n","          subset_normed_train_data = normed_train_data[train_params]\n","          subset_nomred_test_data = normed_test_data[train_params]\n","\n","          linear_model = keras.Sequential()\n","          # Create model, input dim is the number of input variables\n","          linear_model.add(layers.Dense(1, input_dim =len(train_params), activation = \"linear\"))\n","\n","          linear_model.compile(loss=\"mse\", optimizer= \"rmsprop\", metrics= [\"mse\"])\n","\n","          # train model\n","          linear_model.fit(subset_normed_train_data, train_labels[idx_dictList][1], epochs = epoch, verbose = 0)\n","\n","          # make prediction on test data\n","          y_pred=linear_model.predict(subset_nomred_test_data)\n","\n","          # evaluate test data\n","          meanSquared = mse(y_pred,test_labels[idx_dictList][1])\n","          meanAbsolute = mean_absolute_error(y_pred,test_labels[idx_dictList][1])\n","\n","          n = len(test_labels[idx_dictList][1])\n","          x = len(train_params)\n","\n","          R2=r2_score(test_labels[idx_dictList][1],y_pred)\n","          Adjusted_R2=1-((1-R2)*(n-1))/(n-x-1)\n","          SSE = np.sum((output_test_array[idx_dictList] - y_pred) ** 2)\n","          RMSE=meanSquared.mean()**0.5\n","\n","          performance_table_forward_search = performance_table_forward_search.append(\n","              {\n","                \"Label\": train_labels[idx_dictList][0],\n","                \"number_of_features\":len(train_params),\n","                \"features\": train_params,\n","                \"epochs\":epoch,\n","                \"base_mean\":means[idx_dictList][1],\n","                \"meanSquared\":meanSquared.mean(),\n","                \"meanAbsolute\":meanAbsolute,\n","                \"R2\":R2,\n","                \"adj. R2\":Adjusted_R2,\n","                \"SSE\":SSE,\n","                \"RMSE\":RMSE,\n","                \"Diff_base_MAE\": means[idx_dictList][1]-meanAbsolute\n","             },\n","              True\n","          )\n","\n","\n","\n","          performanceList.append(meanAbsolute)\n","          print(\"##################################\")\n","          print(\"Finished |\",epoch,\" |\",train_labels[idx_dictList][0],\" |\",train_params,)\n","          print(\"##################################\")\n","      # close for\n","\n","      # select best feature space\n","\n","      # set new parameter list\n","      if len(features) != 0:\n","        index_best_features=performanceList.index(min(performanceList))\n","        best_features = parameterList[index_best_features]\n","        performanceList = []\n","        parameterList = []\n","        # remove parameter from features\n","        for element in best_features:\n","          if element in features:\n","            features.remove(element)\n","    print(\"end of while\")\n","    dt = datetime.now()\n","\n","    # close while\n","  # end of epoch\n","  postfix = dt.isoformat()+\" \"+ train_labels[idx_dictList][0]+\".csv\"\n","  performance_table_forward_search.to_csv(\"/content/sample_data/performance_table_linear_regression \"+ postfix)\n","  files.download('/content/sample_data/performance_table_linear_regression '+ postfix)"]},{"cell_type":"markdown","source":["Linear Regression single run"],"metadata":{"id":"TbADayxCGF41"}},{"cell_type":"code","source":["normed_train_data = normed_train_data_form\n","normed_test_data = normed_test_data_form"],"metadata":{"id":"nrAcr9E0HijH"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-2DX-VJQgU8W"},"outputs":[],"source":["performance_table_forward_search = pd.DataFrame()"]},{"cell_type":"code","source":["pd.set_option('display.max_columns', None)"],"metadata":{"id":"YG4uSodXH9dq"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LeFsyVUWSjJ-"},"outputs":[],"source":["train_params=\t['map_size', 'num_static_obstacles', 'robot_max_speed',\n","               'crowdnav', 'rlca', 'indoor_map_type', 'mean_angle_info',\n","               'corridor_width', 'robot_radius', 'iterations']\n","idx_of_performance_metric = 4\n","epoch = 500\n","label_array = output_test_array[4]\n","\n","# get subset of training data\n","subset_normed_train_data = normed_train_data[train_params]\n","subset_nomred_test_data = normed_test_data[train_params]\n","\n","linear_model = keras.Sequential()\n","# Create model, input dim is the number of input variables\n","linear_model.add(layers.Dense(1, input_dim =len(train_params), activation = \"linear\"))\n","\n","linear_model.compile(loss=\"mse\", optimizer= \"rmsprop\", metrics= [\"mse\"])\n","\n","# train model\n","linear_model.fit(subset_normed_train_data, train_labels[idx_of_performance_metric][1], epochs = epoch, verbose = 0)\n","\n","# make prediction on test data\n","y_pred=linear_model.predict(subset_nomred_test_data)\n","\n","# evaluate test data\n","meanSquared = mse(y_pred,test_labels[idx_of_performance_metric][1])\n","meanAbsolute = mean_absolute_error(y_pred,test_labels[idx_of_performance_metric][1])\n","\n","\n","n = len(test_labels[idx_of_performance_metric][1])\n","x = len(train_params)\n","\n","R2=r2_score(label_array,y_pred)\n","Adjusted_R2=1-((1-R2)*(n-1))/(n-x-1)\n","SSE = np.sum((output_test_array[0] - y_pred) ** 2)\n","RMSE=meanSquared.mean()**0.5\n","\n","performance_table_forward_search = performance_table_forward_search.append(\n","    {\n","    \"Label\": train_labels[idx_of_performance_metric][0],\n","    \"number_of_features\":len(train_params),\n","    \"features\": train_params,\n","    \"epochs\":epoch,\n","    \"base_mean\":means[idx_of_performance_metric][1],\n","    \"meanSquared\":meanSquared.mean(),\n","    \"meanAbsolute\":meanAbsolute,\n","    \"R2\":R2,\n","    \"adj. R2\":Adjusted_R2,\n","    \"SSE\":SSE,\n","    \"RMSE\":RMSE,\n","    \"Diff_base_MAE\": means[idx_of_performance_metric][1]-meanAbsolute\n","    }, True\n","          )\n","\n","dt = datetime.now()\n","\n","# close while\n","# end of epoch\n","postfix = dt.isoformat()+\" \"+ train_labels[idx_of_performance_metric][0]+\".csv\"\n","performance_table_forward_search.to_csv(\"/content/sample_data/performance_table_linear_regression \"+ postfix)\n"]}],"metadata":{"colab":{"provenance":[{"file_id":"1KVlO9v06i2aOeez9t6UdsZ3_JjvcUZhb","timestamp":1695816369511},{"file_id":"1OyraH-ey6XXoO9hS6GxxdB41FckjzIds","timestamp":1695725359577},{"file_id":"11LX9E2LKLKI2rcwXqYGph9lj5gl_EghT","timestamp":1695638174006},{"file_id":"1JupsVmgPJIsVt5rbMTTtjDch4SsJeC-G","timestamp":1694164828229}],"authorship_tag":"ABX9TyMn9HzYvBEBhnN7U2xVP3Vb"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}